{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMSnpDMvqgNNuqtaufWyqQd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RainXie23/MANE4961---Machine-Learning-for-Engineering-Fall-2025-/blob/main/MLE_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "jzZVns4DN3_d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL9ONwsYHSLC",
        "outputId": "b3e79610-d9b0-43a8-a7dd-f9dfc8898773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['agg', 'doi', 'genbank', 'ipg_id', 'name', 'pdb', 'pdb.0', 'pdb.1',\n",
            "       'pdb.10', 'pdb.2',\n",
            "       ...\n",
            "       'transitions.2.to_state', 'transitions.2.trans_wave',\n",
            "       'transitions.3.from_state', 'transitions.3.to_state',\n",
            "       'transitions.3.trans_wave', 'transitions.4.from_state',\n",
            "       'transitions.4.to_state', 'transitions.4.trans_wave', 'uniprot',\n",
            "       'uuid'],\n",
            "      dtype='object', length=117)\n"
          ]
        }
      ],
      "source": [
        "url = \"https://www.fpbase.org/api/proteins/?format=csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.to_csv(\"fpbase_with_sequences.csv\", index=False)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython\n",
        "from Bio.SeqUtils import molecular_weight\n",
        "\n",
        "df_no_ambiguous = df[df['seq'].apply(lambda x: ('X' not in x and 'Z' not in x and 'B' not in x) if isinstance(x, str) else False)]\n",
        "df_no_ambiguous['mol_weight'] = df_no_ambiguous['seq'].apply(lambda s: molecular_weight(s, seq_type='protein') if isinstance(s, str) else None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkQZlXrAECol",
        "outputId": "a43aa481-157c-4c11-847a-7c7c4353bd98"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-815984273.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_no_ambiguous['mol_weight'] = df_no_ambiguous['seq'].apply(lambda s: molecular_weight(s, seq_type='protein') if isinstance(s, str) else None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_no_ambiguous[\n",
        "    (df_no_ambiguous['switch_type'] == 'b') &\n",
        "    df_no_ambiguous['agg'].notna() &\n",
        "    (df_no_ambiguous['agg'] != '') &\n",
        "    df_no_ambiguous['states.0.em_max'].notna() &\n",
        "    df_no_ambiguous['states.0.brightness'].notna()\n",
        "]\n",
        "\n",
        "len(df['name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQjCCTvkEuz5",
        "outputId": "9709f9d7-11e0-43dc-ad78-99b18de05a3d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "435"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "amino_acids_list = list('ARNDCQEGHILKMFPSTWYV')\n",
        "aaindex = {aa: i for i, aa in enumerate(amino_acids_list)}\n",
        "\n",
        "def Seq2OneHot(seq, amino_acid_alphabet):\n",
        "  max_len = max(len(s) for s in df['seq'])\n",
        "  one_hot_seq = np.zeros((max_len, len(amino_acid_alphabet)))\n",
        "  for i, char in enumerate(seq):\n",
        "    if i < max_len and char in amino_acid_alphabet:\n",
        "      one_hot_seq[i, aaindex[char]] = 1\n",
        "  return one_hot_seq\n",
        "\n",
        "def Position(seq, amino_acid_alphabet):\n",
        "  most_aa_in_seq = 0\n",
        "  if isinstance(seq, str) and len(seq) > 0:\n",
        "    counts = collections.Counter(seq)\n",
        "    if counts:\n",
        "      most_aa_in_seq = max(counts.values())\n",
        "\n",
        "  # Ensure most_aa is at least 1 to avoid issues with empty sequences or zero counts\n",
        "  if most_aa_in_seq == 0 and len(seq) > 0: # If there are AAs but counts are all zero, it's an issue\n",
        "      most_aa_in_seq = 1 # Smallest possible dimension for position if seq is not empty\n",
        "  elif len(seq) == 0:\n",
        "      return np.zeros((len(amino_acid_alphabet), 0)) # Return empty array if sequence is empty\n",
        "\n",
        "  position = np.zeros((len(amino_acid_alphabet), most_aa_in_seq))\n",
        "  aa_occurrence_count = {aa: 0 for aa in amino_acid_alphabet}\n",
        "\n",
        "  for i, char_in_seq in enumerate(seq):\n",
        "    if char_in_seq in aaindex:\n",
        "      aa_index = aaindex[char_in_seq]\n",
        "      occurrence_idx = aa_occurrence_count[char_in_seq]\n",
        "      if occurrence_idx < most_aa_in_seq:\n",
        "          position[aa_index, occurrence_idx] = 1\n",
        "      aa_occurrence_count[char_in_seq] += 1\n",
        "  return position"
      ],
      "metadata": {
        "id": "48Om08_QPJnq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['seq_one_hot'] = df['seq'].apply(lambda s: Seq2OneHot(s, amino_acids_list))\n",
        "df['seq_position'] = df['seq'].apply(lambda s: Position(s, amino_acids_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4cwKKhIoJW4",
        "outputId": "5fb17baf-105f-48b0-9de7-d4ae0bcae991"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-305362229.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['seq_one_hot'] = df['seq'].apply(lambda s: Seq2OneHot(s, amino_acids_list))\n",
            "/tmp/ipython-input-305362229.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['seq_position'] = df['seq'].apply(lambda s: Position(s, amino_acids_list))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Agg2Num(agg):\n",
        "  if agg == 'm':\n",
        "    return 1\n",
        "  elif agg == 'd' or agg == 'wd':\n",
        "    return 2\n",
        "  elif agg == 'td':\n",
        "    return 2.5\n",
        "  elif agg == 't':\n",
        "    return 4\n",
        "  else:\n",
        "    return np.nan # Handle cases where agg might not match known categories"
      ],
      "metadata": {
        "id": "epvyblNtpfly"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np # Ensure numpy is imported if used in this cell for np.array\n",
        "\n",
        "# Create a numeric representation for 'agg'\n",
        "df['agg_numeric'] = df['agg'].apply(Agg2Num)\n",
        "\n",
        "# Define target variables (y) for multi-output regression\n",
        "# Using .values to get a numpy array from the DataFrame subset\n",
        "y = df[['agg_numeric', 'states.0.em_max', 'states.0.brightness']].values\n",
        "\n",
        "# Flatten the 'seq_one_hot' arrays into a 2D numpy array for X\n",
        "# First, determine the maximum sequence length used for one-hot encoding\n",
        "# The 'amino_acids_list' is already defined in a previous cell.\n",
        "max_len_seq = max(len(s) for s in df['seq'])\n",
        "num_amino_acids = len(amino_acids_list) # From aaindex and amino_acids_list in previous cells\n",
        "\n",
        "# Each entry in df['seq_one_hot'] is a numpy array of shape (max_len_seq, num_amino_acids)\n",
        "# We flatten each of these arrays into a 1D vector and stack them.\n",
        "X = np.array([arr.flatten() for arr in df['seq_one_hot']])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKSXPjEjNHTq",
        "outputId": "434b1c28-66ca-4c5b-b4ef-b8da260dfafb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3811481768.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['agg_numeric'] = df['agg'].apply(Agg2Num)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "Ir2OESY3sH92"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the Neural Network model\n",
        "model = Sequential([\n",
        "    Input(shape=(x_train.shape[1],)), # Input layer expects flattened feature vector\n",
        "    Dense(256, activation='relu'), # First hidden layer\n",
        "    Dense(128, activation='relu'), # Second hidden layer\n",
        "    Dense(64, activation='relu'),  # Third hidden layer\n",
        "    Dense(y_train.shape[1])       # Output layer: 3 neurons for 'agg_numeric', 'em_max', 'brightness'\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "# Using Adam optimizer and Mean Squared Error (MSE) loss for regression\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "# Setup Early Stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the Neural Network model...\")\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=100, # Increased epochs, but early stopping will manage it\n",
        "    batch_size=32,\n",
        "    validation_split=0.2, # Use a portion of training data for validation\n",
        "    callbacks=[early_stopping], # Add early stopping callback\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "print(\"\\nEvaluating the model on the test set...\")\n",
        "loss, mae, mse = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Loss (MSE): {loss:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(\"\\nSample predictions vs actual values (first 5 test samples):\")\n",
        "for i in range(5):\n",
        "    print(f\"  Sample {i+1}:\")\n",
        "    print(f\"    Predicted: {y_pred[i]}\")\n",
        "    print(f\"    Actual:    {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD0ZpoEVsNYL",
        "outputId": "90376581-873f-4741-8b1a-c2ff4ace6ae1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the Neural Network model...\n",
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 109112.6094 - mae: 201.0556 - mse: 109112.6094 - val_loss: 94510.6719 - val_mae: 191.0801 - val_mse: 94510.6719\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 93225.2188 - mae: 190.4466 - mse: 93225.2188 - val_loss: 68303.3984 - val_mae: 170.3733 - val_mse: 68303.3984\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 55148.5156 - mae: 153.9451 - mse: 55148.5156 - val_loss: 22206.7734 - val_mae: 89.1603 - val_mse: 22206.7734\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 12845.4717 - mae: 72.5647 - mse: 12845.4717 - val_loss: 13198.9336 - val_mae: 66.5615 - val_mse: 13198.9336\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5836.8926 - mae: 49.6996 - mse: 5836.8926 - val_loss: 10115.4121 - val_mae: 53.3853 - val_mse: 10115.4121\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 3445.3652 - mae: 37.8308 - mse: 3445.3652 - val_loss: 7739.3306 - val_mae: 39.9658 - val_mse: 7739.3306\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1227.5284 - mae: 22.6746 - mse: 1227.5284 - val_loss: 7195.8208 - val_mae: 35.3120 - val_mse: 7195.8208\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 784.1788 - mae: 19.4877 - mse: 784.1788 - val_loss: 8112.9536 - val_mae: 38.5587 - val_mse: 8112.9536\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 597.3318 - mae: 17.1927 - mse: 597.3318 - val_loss: 7537.1777 - val_mae: 34.3318 - val_mse: 7537.1777\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 424.6156 - mae: 13.8563 - mse: 424.6156 - val_loss: 7369.6855 - val_mae: 33.0212 - val_mse: 7369.6855\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 302.9488 - mae: 11.5971 - mse: 302.9488 - val_loss: 7491.4526 - val_mae: 33.5495 - val_mse: 7491.4526\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 308.2592 - mae: 11.6877 - mse: 308.2592 - val_loss: 7365.3418 - val_mae: 31.7177 - val_mse: 7365.3418\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 227.3705 - mae: 9.6600 - mse: 227.3705 - val_loss: 7431.0024 - val_mae: 32.4367 - val_mse: 7431.0024\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 229.0931 - mae: 9.6545 - mse: 229.0931 - val_loss: 7347.5205 - val_mae: 32.0119 - val_mse: 7347.5205\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 199.9276 - mae: 9.2902 - mse: 199.9276 - val_loss: 7387.8774 - val_mae: 31.7233 - val_mse: 7387.8774\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 168.3028 - mae: 8.4208 - mse: 168.3028 - val_loss: 7368.2231 - val_mae: 31.4286 - val_mse: 7368.2231\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 175.2449 - mae: 8.3303 - mse: 175.2449 - val_loss: 7343.4185 - val_mae: 31.5221 - val_mse: 7343.4185\n",
            "Model training complete.\n",
            "\n",
            "Evaluating the model on the test set...\n",
            "Test Loss (MSE): 6925.9863\n",
            "Test MAE: 38.4810\n",
            "Test MSE: 6925.9863\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "Sample predictions vs actual values (first 5 test samples):\n",
            "  Sample 1:\n",
            "    Predicted: [ 11.426594 725.23706   37.0677  ]\n",
            "    Actual:    [  1.   720.     6.13]\n",
            "  Sample 2:\n",
            "    Predicted: [  5.8934474 520.787      35.552692 ]\n",
            "    Actual:    [  1.   449.    22.79]\n",
            "  Sample 3:\n",
            "    Predicted: [2.5535142e-01 4.9323892e+02 3.5671315e+00]\n",
            "    Actual:    [  1.   503.    25.35]\n",
            "  Sample 4:\n",
            "    Predicted: [  1.1320472 163.82721    12.905148 ]\n",
            "    Actual:    [  1.  496.   15.5]\n",
            "  Sample 5:\n",
            "    Predicted: [  5.791262 491.88773   34.206295]\n",
            "    Actual:    [  1.   502.    43.09]\n"
          ]
        }
      ]
    }
  ]
}